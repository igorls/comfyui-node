{
  "1": {
    "inputs": {
      "model_name": "svdq-int4_r32-qwen-image-edit-2509-lightningv2.0-4steps.safetensors",
      "cpu_offload": "auto",
      "num_blocks_on_gpu": 1,
      "use_pin_memory": "disable"
    },
    "class_type": "NunchakuQwenImageDiTLoader",
    "_meta": {
      "title": "Nunchaku Qwen-Image DiT Loader"
    }
  },
  "2": {
    "inputs": {
      "seed": 625457843346685,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "1",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "5",
        0
      ],
      "latent_image": [
        "6",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "3": {
    "inputs": {
      "prompt": "change her t-shirt color to red",
      "clip": [
        "8",
        0
      ],
      "vae": [
        "7",
        0
      ],
      "image": [
        "4",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEdit",
    "_meta": {
      "title": "TextEncodeQwenImageEdit"
    }
  },
  "4": {
    "inputs": {
      "image": "chroma-weave_studio_serenity_leaning_against_the_wall_img-1760088256888.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "5": {
    "inputs": {
      "conditioning": [
        "3",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "6": {
    "inputs": {
      "pixels": [
        "4",
        0
      ],
      "vae": [
        "7",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "7": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "8": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "9": {
    "inputs": {
      "samples": [
        "2",
        0
      ],
      "vae": [
        "7",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "10": {
    "inputs": {
      "images": [
        "9",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}